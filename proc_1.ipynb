{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kh7ikCw1dWx5"
   },
   "source": [
    "# GRO620 - Activité procédurale 1\n",
    "\n",
    "Dans cette activité, nous allons principalement travailler sur les éléments nécessaires pour capter une image numériquement, les transformations entre repères 2D et 3D, et l'encodage numérique de la couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45339,
     "status": "ok",
     "timestamp": 1622381462155,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "pC6BnG_3dWyA",
    "outputId": "4486fcd9-17b2-4018-e963-c0b64774adcc",
    "ExecuteTime": {
     "end_time": "2023-07-24T13:00:51.893089Z",
     "start_time": "2023-07-24T13:00:49.922172700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Préambule\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Si vous utilisez Google Colab, vous devez d'abord monter votre Google Drive\n",
    "## où se trouve vos données. \n",
    "## Commentez les trois lignes suivantes en ajustant le chemin vers votre propre\n",
    "## dossier :\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd /content/gdrive/MyDrive/gro620-e21\n",
    "\n",
    "## Pour retrouver le chemin depuis Jupyter, vous pouvez utiliser ceci :\n",
    "# !ls /content/gdrive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1xSdXoMdWyB"
   },
   "source": [
    "## Acquisition et caractéristiques de la lumière\n",
    "\n",
    "### Q1.1\n",
    "\n",
    "À partir de la figure 2.23 du livre de référence, décrivez en une phrase le rôle de chacune des étapes de la chaîne d'acquisition d'images numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPRDNqrrdWyB"
   },
   "source": [
    "*Optics: Sert à concentrer la lumière, l'agrandir et la recentrer sur le capteur.*\n",
    "\n",
    "*Aperture: Sert à agrandir ou rétrécir l'ouverture de la caméra pour gérer la quantité de lumière qui entre. (Quand il fait noir, ou flouter l'image)*\n",
    "\n",
    "*Shutter: Sert à modifier le temps d'exposition du capteur à la lumière. (Si il fait noir, plus de temps d'exposition, si on bouge, plus le temps est long, plus l'objet va être flou)*\n",
    "\n",
    "*Sensor: Sert à transformer les photons en signal électrique analogique.*\n",
    "\n",
    "*Gain(ISO):Amplifie le signal analogique pour couvrir la totalité de la plage du dynamique du capteur. (Ça ajoute du bruit)*\n",
    "\n",
    "*ADC:Permet de convertir le signal analogique en signal digital.*\n",
    "\n",
    "*Demosaic: (Color filter array) Filtre de couleur pour améliorer la qualité de l'image. On passe par une matrice qui isole une couleur dans un canal et fait une moyenne des voisins pour reconstruire les couleurs manquante dans le canal. (Figure 2.31(a))*\n",
    "\n",
    "*Denoise and sharpen: Permet de corriger le floutage du CFA et applique un filtre passe haut ou bas pour diminuer le bruit.*\n",
    "\n",
    "*White balance: Ramener ce qui devait être blanc en un vrai blanc.*\n",
    "\n",
    "*Gamma/curve: Permet de faire correspondre les valeurs numériques dans la facon que la valeur numérique est perçu par l'oeil. (Corrige la réponse naturelle de l'oeil)*\n",
    "\n",
    "*Compress: Compresse l'image pour prendre moins de place.(Désavantage c'est qu'on dégrade l'information de l'image)*\n",
    "\n",
    "*RAW: Permet de garder toute l'information de l'image et ça skip le post-processing parce qu'on peut faire mieux pour le post-processing*\n",
    "\n",
    "*JPEG: Perte de la résolution de la couleur.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdxhihn2dWyB"
   },
   "source": [
    "### Q1.2\n",
    "\n",
    "Quelle est la différence entre les paramètres intrinsèques et extrinsèques d'une caméra ? Décrivez chaque type en une phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiFuS6rPdWyC"
   },
   "source": [
    "Intrinsèques: Ce qui est dans l'appareil. (Taille du capteur, la lentille, ...)\n",
    "Extrinsèques: Ce qui est à l'extérieur de la caméra. (où elle est installé.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FWZECptdWyC"
   },
   "source": [
    "### Q1.3\n",
    "\n",
    "Soit la configuration intrinsèque d'une caméra représentée par la matrice $K$ (Certains fabricants vont nous donner la matrice K, mais sinon, il faut faire la calibration pour la trouver) :\n",
    "\n",
    "$$\n",
    "K = \\begin{bmatrix} \n",
    " 620 &   0 & 1024 \\\\ \n",
    "   0 & 620 &  512 \\\\ \n",
    "   0 &   0 &    1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Le capteur de cette caméra a une taille de 30 mm x 15 mm.\n",
    "\n",
    "Pouvez-vous estimer la distance focale en mm de la lentille de cette caméra à partir de la matrice $K$ ? (Voir notes de cour page 58)\n",
    "\n",
    "*La matrice K est uniquement en pixels, il faut donc les informations du capteur pour convertir en mm.*\n",
    "\n",
    "*La raison pourquoi W et H sont divisé par deux c'est parce que c'est le centre de l'image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mcfUfXCCdWyC",
    "ExecuteTime": {
     "end_time": "2023-07-24T14:07:11.373360900Z",
     "start_time": "2023-07-24T14:07:11.354022600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance focale x:  9.08203125\n",
      "Distance focale y:  9.08203125\n",
      "Les pixels peuvent ne pas être carré ce qui donne deux distance focale en pixels différentes\n"
     ]
    }
   ],
   "source": [
    "# Réponse ici.\n",
    "K = np.array([[620.,   0., 1024.],\n",
    "              [  0., 620.,  512.],\n",
    "              [  0.,   0.,    1.]\n",
    "])\n",
    "Wp = K[0,2]*2\n",
    "Hp = K[1,2]*2\n",
    "Wm = 30/Wp  #(mm/px)\n",
    "Hm = 15/Hp  #(mm/px)\n",
    "fx = K[0,0]* Wm\n",
    "fy = K[1,1]*Hm\n",
    "print(\"Distance focale x: \", fx)\n",
    "print(\"Distance focale y: \", fy)\n",
    "print(\"Les pixels peuvent ne pas être carré ce qui donne deux distance focale en pixels différentes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quJcFsPbdWyD"
   },
   "source": [
    "### Q1.4\n",
    "\n",
    "Dans le cadre de cet APP, nous considérons les caméras comme étant idéales, c'est-à-dire qu'on peut obtenir leurs caractéristiques intrinsèques et extrinsèques à partir de quelques paramètres seulement. (p.79)\n",
    "\n",
    "**a)** Qu'est-ce qui rend les vraies caméras non-idéales ? Nommez des facteurs autant pour les caractéristiques intrinsèques que extrinsèques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erl2fPTidWyD"
   },
   "source": [
    "*Intrinsèque: Toutes les réalités d'une chaine de manufactures, défauts et autres comme dans la lentille, le boitier, ...*\n",
    "*Extrinsèque: Une mauvaise mesure dans la position de la caméra dans l'environnement*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sfg46RtdWyD"
   },
   "source": [
    "**b)** Que doit on faire pour obtenir les caractéristiques d'une caméra non-idéale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bezo06eCdWyE"
   },
   "source": [
    "*Calibrer la caméra avec un outil de calibration comme le panneaux à damiers, ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.5\n",
    "\n",
    "Dans cette image synthétique (p.67):\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/cd/Specular_highlight.jpg)\n",
    "\n",
    "(source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Specular_highlight.jpg))\n",
    "\n",
    "**a)** Quelle(s) partie(s) correspondent à l'illumination diffuse et les reflets spéculaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yFIYACqdXa3"
   },
   "source": [
    "*Diffuse: Les parties jaune de l'image, c'est ce qui donne la couleur.*\n",
    "*Spéculaire: Les parties qui sont très blanches. (Gloss or Higlight)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXkcFjFKdXa4"
   },
   "source": [
    "**b)** Quelle information est nécessaire pour déterminer les caractéristiques et emplacements exacts des sources de lumières dans cette image ? Vous pouvez répondre en utilisant des éléments de la *Bidirectional Reflectance Distribution Function* (BRDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGntKizNdXa5",
    "tags": []
   },
   "source": [
    "*Ce n'est pas possible, car ça implique beaucoup de données qu'on ne connait pas*\n",
    "*On peut avec les deux boules estimer la position de la lumière en joignant les deux vecteurs normaux des points blancs de la réflexion spéculaire.*\n",
    "*Avec une caméra stéréoscopique*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.6\n",
    "\n",
    "**a)** Pourquoi deux appareils de capture peuvent produire des valeurs RGB différentes d'une même couleur ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4LmStT2f6C1"
   },
   "source": [
    "*S'ils ne sont pas calibrer de la bonne façon, les capteurs ont des tolérances et ainsi de suite, donc il est peu probable*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obSsXTc8f5XM"
   },
   "source": [
    "**b)** Que peut-on faire pour comparer numériquement des couleurs provenant de deux capteurs différents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ629ialf4VV"
   },
   "source": [
    "*Avec l'espace de couleur x,y,z. (Voir figure 2.30)*\n",
    "*On peut donc comparer si on a les deux matrices de conversion vers le x,y,z des deux capteurs*\n",
    "*Le lab: ressemble à x,y,z, mais il as été conçu pour que la distance euclidienne soit proportionnelle à ce que l'oeil perçoit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKQOpwTVdWyE"
   },
   "source": [
    "## Repères et coordonnées\n",
    "\n",
    "### Q2.1\n",
    "\n",
    "Supposons ces 2 repères :\n",
    "\n",
    "![](images_doc/proc1-q2_1-frames.png)\n",
    "\n",
    "**a)** Trouvez la matrice homogène permettant de transformer un point du repère $\\{1\\}$ au repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jULxdVBsdWyE",
    "outputId": "630316fc-4340-46fa-aa1f-54f653075553",
    "ExecuteTime": {
     "end_time": "2023-07-24T15:00:08.198064200Z",
     "start_time": "2023-07-24T15:00:08.183415800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_10:\n",
      " [[ 0.    1.    0.    0.24]\n",
      " [ 1.    0.    0.    0.8 ]\n",
      " [ 0.    0.   -1.    0.12]\n",
      " [ 0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Aligner le repère sur l'autre pour avoir la matrice de rotation et ensuite la dernière colonne est la translation.\n",
    "T_10 = np.array([[0, 1, 0, .24],\n",
    "                 [1, 0, 0, 0.8],\n",
    "                 [0, 0, -1, 0.12],\n",
    "                 [0, 0, 0, 1]])\n",
    "print(\"T_10:\\n\", T_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJIOwDUPdWyF"
   },
   "source": [
    "**b)** Trouvez maintenant la transformation inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LH35FSWqdWyG",
    "ExecuteTime": {
     "end_time": "2023-07-24T15:01:19.772567Z",
     "start_time": "2023-07-24T15:01:19.670577400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_01:\n",
      " [[ 0.    1.    0.   -0.8 ]\n",
      " [ 1.    0.    0.   -0.24]\n",
      " [-0.   -0.   -1.    0.12]\n",
      " [ 0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "T_01 = np.linalg.inv(T_10)\n",
    "print(\"T_01:\\n\", T_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2ximr9WdWyG"
   },
   "source": [
    "**c)** Soit le point $p_0 = [8, 5, 1]^T$, un point dans le repère $\\{0\\}$. Trouvez $p_1$, ses coordonnées dans le repère $\\{1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b22z2cUnf0WF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nj0k5hkLdWyG",
    "ExecuteTime": {
     "end_time": "2023-07-24T15:03:39.979454200Z",
     "start_time": "2023-07-24T15:03:39.975433800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_1:\n",
      " [ 4.2   7.76 -0.88  1.  ]\n"
     ]
    }
   ],
   "source": [
    "# On ajoute un 1 à la fin pour permettre de faire la translation et l'inversion de la matrice.\n",
    "p_0 = [8, 5, 1, 1]\n",
    "p_1 = T_01 @ p_0\n",
    "print(\"P_1:\\n\", p_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPkWLvBydWyH"
   },
   "source": [
    "### Q2.2\n",
    "\n",
    "Supposons maintenant que le repère $\\{1\\}$ représente une caméra avec les caractéristiques intrinsèques $K$ de la question Q1.3.\n",
    "\n",
    "**a)** Trouvez la matrice de projection P complète permettant de projeter un point $p$ décrit dans le repère $\\{0\\}$. (équation 2.64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6XhSj3FRdWyH",
    "outputId": "ab32f10e-8b2c-4cea-ed94-5ec725bbe94c",
    "ExecuteTime": {
     "end_time": "2023-07-24T15:49:23.510905800Z",
     "start_time": "2023-07-24T15:49:23.496373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_:\n",
      " [[6.200e+02 0.000e+00 1.024e+03 0.000e+00]\n",
      " [0.000e+00 6.200e+02 5.120e+02 0.000e+00]\n",
      " [0.000e+00 0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00]]\n",
      "P:\n",
      " [[ 0.0000e+00  6.2000e+02 -1.0240e+03 -3.7312e+02]\n",
      " [ 6.2000e+02  0.0000e+00 -5.1200e+02 -8.7360e+01]\n",
      " [ 0.0000e+00  0.0000e+00 -1.0000e+00  1.2000e-01]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "z = T_10[2,3]\n",
    "R = T_01[0:3,0:3]\n",
    "t = T_01[0:3,3]\n",
    "Zero = np.zeros((3,1))\n",
    "K_ = np.array([[K[0,0], K[0,1], K[0,2], 0],\n",
    "               [K[1,0], K[1,1], K[1,2], 0],\n",
    "               [K[2,0], K[2,1], K[2,2], 0],\n",
    "               [0, 0, 0, 1]])\n",
    "print(\"K_:\\n\", K_)\n",
    "\n",
    "P = K_ @ T_01\n",
    "print(\"P:\\n\", P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UEWupgIdWyI"
   },
   "source": [
    "**b)** Soit le point $p_0 = [0.250, 0.010, 0.000]$. Trouvez le point $x_s$, les coordonnées du point $p_0$ perçu par la caméra. (Équation 2.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WryXyIycdWyI",
    "ExecuteTime": {
     "end_time": "2023-07-24T15:49:26.690947400Z",
     "start_time": "2023-07-24T15:49:26.687650400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_s:\n",
      " [-3.6692e+02  6.7640e+01  1.2000e-01  1.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.array([0.250, 0.010, 0.000, 1])\n",
    "x_s = P @ p_0\n",
    "print(\"x_s:\\n\", x_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "On y est presque, il suffit de"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs:\n",
      " [-3.05766667e+03  5.63666667e+02  1.00000000e+00  8.33333333e+00]\n"
     ]
    }
   ],
   "source": [
    "xs = x_s/z\n",
    "print(\"xs:\\n\", xs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T15:49:28.606039600Z",
     "start_time": "2023-07-24T15:49:28.602006700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpa--SomdWyY"
   },
   "source": [
    "## Reprojection 2D à 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVHRnJsIdWyY"
   },
   "source": [
    "### Q3.1\n",
    "\n",
    "Supposons que le plan XY du repère $\\{0\\}$ est un convoyeur. Quelle serait sa largeur maximale (mesurée sur l'axe Y) si on souhaite que la caméra la capte au complet dans son image ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WqHjEONdWyZ"
   },
   "outputs": [],
   "source": [
    "l_conv = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk6xchjCdWyZ"
   },
   "source": [
    "### Q3.2\n",
    "\n",
    "Soit le point $x_s = [120, 200]$, un point dans l'image perçu par la caméra décrite plus haut. On suppose que le point perçu se trouve sur le plan XY du repère $\\{0\\}$. Trouvez les coordonnées du point $p_0$ qui correspond à ce même point dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "GYiNDm-BdWya",
    "ExecuteTime": {
     "end_time": "2023-07-24T15:44:04.759927300Z",
     "start_time": "2023-07-24T15:44:04.747796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_s:\n",
      " [14.4  24.    0.12  1.  ]\n"
     ]
    }
   ],
   "source": [
    "disparity = 1/z\n",
    "x_s = np.array([120,200,1,disparity])\n",
    "x_s = x_s * z\n",
    "print(\"x_s:\\n\", x_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "proc_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
